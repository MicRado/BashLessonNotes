****************************************************************************************************************************************************************************
Good Rules to Follow
****************************************************************************************************************************************************************************
- Always double quote variables, including subshells. No naked $ signs
    - This rule gets you pretty far. Read http://mywiki.wooledge.org/Quotes for details
- All code goes in a function. Even if it's one function, main.
    - Unless a library script, you can do global script settings and call main. That's it.
    - Avoid global variables. Though when defining constants use readonly
- Always have a main function for runnable scripts, called with main or main "$@"
    - If script is also usable as library, call it using [[ "$0" == "$BASH_SOURCE" ]] && main "$@"
- Always use local when setting variables, unless there is reason to use declare
    - Exception being rare cases when you are intentionally setting a variable in an outer scope.
- Variable names should be lowercase unless exported to environment.
- Always use set -eo pipefail. Fail fast and be aware of exit codes.
    - Use || true on programs that you intentionally let exit non-zero.
- Never use deprecated style. Most notably:
    - Define functions as myfunc() { ... }, not function myfunc { ... }
    - Always use [[ instead of [ or test
    - Never use backticks, use $( ... )
        - See http://wiki.bash-hackers.org/scripting/obsolete for more
- Prefer absolute paths (leverage $PWD), always qualify relative paths with ./.
- Always use declare and name variable arguments at the top of functions that are more than 2-lines
    - Example: declare arg1="$1" arg2="$2"
    - The exception is when defining variadic functions. See below.
- Use mktemp for temporary files, always cleanup with a trap.
- Warnings and errors should go to STDERR, anything parsable should go to STDOUT.
- Try to localize shopt usage and disable option when finished.

****************************************************************************************************************************************************************************
Best Practices and Tips
****************************************************************************************************************************************************************************
- Use Bash variable substitution if possible before awk/sed.
- Generally use double quotes unless it makes more sense to use single quotes.
- For simple conditionals, try using && and ||.
- Don't be afraid of printf, it's more powerful than echo.
- Put then, do, etc on same line, not newline.
- Skip [[ ... ]] in your if-expression if you can test for exit code instead.
- Use .sh or .bash extension if file is meant to be included/sourced. Never on executable script.
- Put complex one-liners of sed, perl, etc in a standalone function with a descriptive name.
- Good idea to include [[ "$TRACE" ]] && set -x
- Design for simplicity and obvious usage.
    - Avoid option flags and parsing, try optional environment variables instead.
    - Use subcommands for necessary different "modes".
- In large systems or for any CLI commands, add a description to functions.
    - Use - declare desc="description" at the top of functions, even above argument declaration.
    - This can be queried/extracted using reflection. For example:
EXAMPLE:
eval $(type FUNCTION_NAME | grep 'declare desc=') && echo "$desc"

- Be conscious of the need for portability. Bash to run in a container can make more assumptions than Bash made to run on multiple platforms.
- When expecting or exporting environment, consider namespacing variables when subshells may be involved.
- Use hard tabs. Heredocs ignore leading tabs, allowing better indentation.

****************************************************************************************************************************************************************************
Expand argument lists
****************************************************************************************************************************************************************************
Double-quoting $@ or ${array[@]} has a special meaning. "$@" expands to a list of words, with each positional parameter's value being one word. Likewise, "${array[@]}" expands to a list of words, one per array element. When dealing with the positional parameters or with the contents of an array as a list of words, always use the double-quoted syntax.

Double-quoting $* or ${array[*]} results in one word which is the concatenation of all the positional parameters (or array elements) with the first character of IFS between them. This is similar to the join function in some other languages, although the fact that you can only have a single join character can sometimes be a crippling limitation.

****************************************************************************************************************************************************************************
Using Quotes
****************************************************************************************************************************************************************************
In many languages, quotes are primarily used to denote string literals. In the shell paradigm, many constructs are interpreted as strings by default, so quotes play other important roles. Quotes demarcate the arguments of a command into units called "words", as well as modify the evaluation of their contents in numerous context-dependent ways. It is critical to understand how quoting affects the interpretation of code in a given context; it's something no one should avoid learning. Improper quoting is among the most common shell programming errors. Do not guess about quotes!

cp $file $destination         # WRONG
cp -- "$file" "$destination"  # RIGHT

Types of quoting
There are three standard types of quotes (or four if you count backslash escaping), and two nonstandard Bash extensions.

Single quotes: 
    '...' removes the special meaning of every character between the quotes. Everything inside single quotes becomes a literal string. The only character that you can't           safely enclose in single quotes is a single quote.

Double quotes: 
    "..." prevents some substitutions but allows others. Every substitution that begins with a dollar sign $ is performed, as is the legacy `...` (backtick) command               substitution. Backslash escaping is also performed. No word splitting or filename expansion is performed.

Backticks: 
    `...` is the legacy command substitution syntax; deprecated in favor of $(...) but still permitted for historical reasons. 

Backslash: 
    Putting \ in front of a metacharacter removes its special meaning. This works inside double quotes, or in the absence of quotes. It does not work inside single quotes.

$'...': 
    Contents are a single word with interpretation of backslash escape sequences such as \n for newline, \t for tab, and \xnn for bytes specified in hexadecimal. These may be     used to specify a text representation of arbitrary data. No current implementation supports a context where these are not interpreted as NUL-terminated C strings.

You can mix the various types of quoting if you need to. For example, if you have one section of a string that has lots of special characters that you'd like to single-quote, and another section with a parameter expansion in it which must be double-quoted.

$ foo=bar
$ printf '%s\n' '!%$*&'"$foo"
!%$*&bar

****************************************************************************************************************************************************************************
General
****************************************************************************************************************************************************************************
Always use long parameter notation when available. This makes the script more readable, especially for lesser known/used commands that you don’t remember all the options for.

EXAMPLE:
 # Avoid:
  rm -rf -- "${dir}"
# Good:
  rm --recursive --force -- "${dir}"

Don’t use:
cd "${foo}"
[...]
cd ..
but
(
  cd "${foo}"
  [...]
)

***pushd*** Command saves your current directory in a stack and then changes to a new directory. 
Save the Current Directory: The current directory is saved in a stack.
Change to a New Directory: You specify a new directory to change to.
EXAMPLE:
    pushd /path/to/new/directory
After running this command, you are now in /path/to/new/directory, and your previous directory has been saved.

***popd*** Command
The popd command removes the top directory from the stack and changes back to it. This lets you return to the directory you were in before using pushd.
Use nohup foo | cat & if foo must be started from a terminal and run in the background.
cd ~ # (home) directory
pushd /usr/local              # Add (home) to stack and switch to /usr/local
echo "Now in $(pwd)"          # Outputs: Now in /usr/local
pushd /tmp                    # Add /usr/local to stack and switch to /tmp
echo "Now in $(pwd)"          # Outputs: Now in /tmp
popd                          # Pop the directory stack, returning to /usr/local
echo "Back to $(pwd)"         # Outputs: Back to /usr/local
popd                          # Pop the directory stack again, returning to home
echo "Back to $(pwd)"         # Outputs: Back to ~

****************************************************************************************************************************************************************************
Variables
****************************************************************************************************************************************************************************
- Prefer local variables within functions over global variables
- If you need global variables, make them readonly
- Variables should always be referred to in the ${var} form (as opposed to $var).
- Variables should always be quoted, especially if their value may contain a whitespace or separator character: "${var}"
- Capitalization:
        - Environment (exported) variables: ${ALL_CAPS}
        - Local variables: ${lower_case}
- Positional parameters of the script should be checked, those of functions should not
- Some loops happen in subprocesses, so don’t be surprised when setting variabless does nothing after them. Use stdout and greping to communicate status.

****************************************************************************************************************************************************************************
Substitution
****************************************************************************************************************************************************************************
Always use $(cmd) for command substitution (as opposed to backquotes)
- $(command) - GOOD
- `command` - BAD

Aliases and builtins in Bash can sometimes override commands. To ensure you are using the actual command (and not an alias or builtin), you can prepend the command with a backslash (\).
EXAMPLE:
\ls  # This will bypass the alias and use the actual 'ls' command - GOOD
alias ls='ls --color=auto'        -v
ls  # This will use the alias      - BAD

EXAMPLE:
\time bash -c "dnf list installed | wc -l"

SYNTAX:
    \time 
        ensures that the actual time command is used, not an alias or a built-in version
    bash -c "dnf list installed | wc -l" 
        runs the command dnf list installed | wc -l in a new Bash shell.
    dnf list installed 
        lists all installed packages.
    | wc -l 
        counts the number of lines in the output of the dnf command, giving the number of installed packages.
****************************************************************************************************************************************************************************
Output and redirection
****************************************************************************************************************************************************************************
For various reasons, printf is preferable to echo. printf gives more control over the output, it’s more portable and its behaviour is defined better.
Print error messages on stderr. 
error() {
    printf "${red}!!! %s${reset}\\n" "${*}" 1>&2
  }

SYNTAX:
    error() {
        This defines a function named error.
    ${red} and ${reset}
        These are variables presumably containing ANSI escape codes for coloring text. The actual values of these variables are not shown, but typically, ${red} would set the         text color to red, and ${reset} would reset the text color back to default.
    !!!
        This is a prefix indicating an error message
    %s 
        This is a format specifier in printf that will be replaced by the string passed to the function.
    ${*}
        This expands to all the arguments passed to the function.
    \\n 
        This is a newline character
    1> 
        This redirects the standard output (stdout), which is file descriptor 1.
    &2
        This indicates that stdout should be redirected to the same location as stderr, which is file descriptor 2.

So, the printf statement constructs an error message with a red prefix and resets the text color afterward, followed by a newline.

When combining a sudo command with redirection, it’s important to realize that the root permissions only apply to the command, not to the part after the redirection operator. An example where a script needs to write to a file that’s only writeable as root:
# Will Not Work:
  sudo printf "..." > /root/some_file

# Will Work:
  printf "..." | sudo tee /root/some_file > /dev/null
****************************************************************************************************************************************************************************
Functions
****************************************************************************************************************************************************************************
Bash can be hard to read and interpret. Using functions can greatly improve readability. Principles from Clean Code apply here.
    - Apply the Single Responsibility Principle: a function does one thing.
    - Don’t mix levels of abstraction
    - Describe the usage of each function: number of arguments, return value, output
    - Declare variables with a meaningful name for positional parameters of functions

foo() {
    local first_arg="${1}"
    local second_arg="${2}"
    [...]
}
    # `foo()` and `bar` as a function name in examples and tutorials is a long-standing convention in programming. It serves as a placeholder name when the actual function        #  name is not important to the explanation or when the example is intended to be generic.

Create functions with a meaningful name for complex tests
EXAMPLE:
# Don't do this
  if [ "$#" -ge "1" ] && [ "$1" = '-h' ] || [ "$1" = '--help' ] || [ "$1" = "-?" ]; then
    usage
    exit 0
  fi

  # Do this
  help_wanted() {
    [ "$#" -ge "1" ] && [ "$1" = '-h' ] || [ "$1" = '--help' ] || [ "$1" = "-?" ]
  }

  if help_wanted "$@"; then
    usage
    exit 0
  fi

SYNTAX:
    help_wanted() {
        This defines a function named help_wanted.
    [ "$#" -ge "1" ]
        This checks if there is at least one argument provided to the script ("$#" is the number of arguments).
    [ "$1" = '-h' ]
        This checks if the first argument ("$1") is -h.
    [ "$1" = '--help' ]
        This checks if the first argument ("$1") is --help.
    [ "$1" = "-?" ]
        This checks if the first argument ("$1") is -?.
Logical Operators:
    The && and || operators are used to combine these conditions:
    && (logical AND) 
        ensures that if there is at least one argument, it must be one of the help options.
    || (logical OR) 
        ensures that any of the specified help options will trigger the condition.
Using the Function:    
    help_wanted "$@"
        Calls the help_wanted function with all the arguments passed to the script ("$@" represents all the script's arguments).
    Action
        If the help_wanted function returns true (i.e., the script was called with a help option), the script calls the usage function and then exits.

****************************************************************************************************************************************************************************
Cleanup code
****************************************************************************************************************************************************************************
An idiom for tasks that need to be done before the script ends (e.g. removing temporary files, etc.). The exit status of the script is the status of the last statement before the finish function.

EXAMPLE:
    finish() {
      result=$?
      echo "Cleaning up before exit..."
      # Remove temporary file if it exists
      [ -f /tmp/tempfile ] && rm -f /tmp/tempfile
      exit ${result}
    }
    # Set up trap to call finish on exit or error
    trap finish EXIT ERR
    # Main script logic
    echo "Creating temporary file..."
    touch /tmp/tempfile
    # Simulate some operations
    echo "Performing operations..."
    # An intentional command that fails
    ls /nonexistentfile
    echo "This line will not be reached if the script exits on error."

SYNTAX:
finish() {
This defines a function named finish.
    result=$?
        This line captures the exit status of the last executed command before the finish function is called. In Bash, $? holds the exit status of the most recently executed          command. Storing this value in the result variable ensures that the original exit status of the script is preserved and can be used later.
    # Your cleanup code here:
        This is a placeholder comment where you can insert any necessary cleanup operations. For example, you might want to remove temporary files, close network connections, 
        or perform other resource management tasks.

    [ -f /tmp/tempfile ]
        This is a test expression enclosed in square brackets, which is a synonym for the test command.
    -f 
        is a test operator that checks if a file exists and is a regular file (not a directory or other special type of file).
    /tmp/tempfile 
        is the file path being checked.
        The expression [ -f /tmp/tempfile ] returns true (exit status 0) if the file /tmp/tempfile exists and is a regular file, and false (non-zero exit status) otherwise.
    &&:
        This is a logical AND operator. In Bash, && is used to execute the command following it only if the preceding command (or test) succeeds (returns a true value).
    rm -f /tmp/tempfile:
        rm is the command to remove (delete) files.
        -f is an option for rm that stands for "force." It forces the removal of the file without prompting for confirmation, even if the file has write-protection, and it            suppresses error messages if the file does not exist.    
    exit ${result}
        This line exits the script with the original exit status that was captured in the result variable. By using exit ${result}, the script ensures that the exit status            reflects the outcome of the script's main operations rather than the status of the cleanup process.

- The trap command ensures that the finish function is called whenever the script exits or an error occurs.
- When the script tries to list a non-existent file (ls /nonexistentfile), it triggers an ERR event.
- The finish function is called, which captures the exit status of the failed ls command and performs cleanup (removing the temporary file).
- The script exits with the same status as the failed ls command, ensuring that the exit status accurately reflects the script's outcome.

Source: Aaron Maxwell, How “Exit Traps” can make your Bash scripts way more robust and reliable.
http://redsymbol.net/articles/bash-exit-traps/
****************************************************************************************************************************************************************************
Writing robust scripts and debugging
****************************************************************************************************************************************************************************
Bash is not very easy to debug. There’s no built-in debugger like you have with other programming languages. By default, undefined variables are interpreted as empty strings, which can cause problems further down the line. A few tips that may help:
    - Always check for syntax errors by running the script with bash -n myscript.sh
      -n: This option tells Bash to perform a syntax check only. It parses the script and looks for syntax errors but does not execute any of the commands in the script.
    - Use ShellCheck and fix all warnings. This is a static code analyzer that can find a lot of common bugs in shell scripts. Integrate ShellCheck in your text editor (e.g.        Syntastic plugin in Vim)
    - Abort the script on errors and undbound variables. Put the following code at the beginning of each script.    
            set -o errexit   # abort on nonzero exitstatus
            set -o nounset   # abort on unbound variable
            set -o pipefail  # don't hide errors within pipes
            
A shorter version is shown below, but writing it out makes the script more readable.
            set -euo pipefail

Use Bash’s debug output feature. This will print each statement after applying all forms of substitution (parameter/command substitution, brace expansion, globbing, etc.)
    - Run the script with bash -x myscript.sh
    - Put set -x at the top of the script
    - If you only want debug output in a specific section of the script, put set -x before and set +x after the section.
Write lots of log messages to stdout or stderr so it’s easier to drill down to what part of the script contains problematic code.
